"""
==================================================================================
                    CUSTOM IMAGE PROCESSING ALGORITHMS
==================================================================================

T·∫≠p h·ª£p c√°c thu·∫≠t to√°n x·ª≠ l√Ω ·∫£nh ƒë∆∞·ª£c t·ª± implement t·ª´ ƒë·∫ßu (kh√¥ng d√πng OpenCV).
T·∫•t c·∫£ thu·∫≠t to√°n ch·ªâ s·ª≠ d·ª•ng NumPy cho t√≠nh to√°n ma tr·∫≠n.

üì¶ MODULE STRUCTURE:
    1. CONVOLUTION & FILTERING - L·ªçc v√† l√†m m·ªãn ·∫£nh
    2. EDGE DETECTION - Ph√°t hi·ªán bi√™n v√† gradient
    3. THRESHOLDING - Ph√¢n ng∆∞·ª°ng v√† ph√¢n ƒëo·∫°n ·∫£nh
    4. MORPHOLOGICAL OPERATIONS - X·ª≠ l√Ω h√¨nh th√°i h·ªçc
    5. ENHANCEMENT - TƒÉng c∆∞·ªùng ch·∫•t l∆∞·ª£ng ·∫£nh
    6. UTILITY FUNCTIONS - C√°c h√†m ti·ªán √≠ch

üéØ FEATURES:
    ‚úÖ 11 thu·∫≠t to√°n x·ª≠ l√Ω ·∫£nh ch√≠nh
    ‚úÖ H·ªó tr·ª£ c·∫£ ·∫£nh grayscale v√† RGB
    ‚úÖ T·ª± ƒë·ªông x·ª≠ l√Ω padding v√† normalization
    ‚úÖ Code t·ªëi ∆∞u v·ªõi NumPy vectorization

üë®‚Äçüíª AUTHOR: DuyPNKD
üìÖ DATE: 2025
üìö COURSE: Image Processing - Semester 6

==================================================================================
"""

import numpy as np


# ==================== CONVOLUTION & FILTERING ====================

def create_gaussian_kernel(size: int, sigma: float = 1.0) -> np.ndarray:
    """
    T·∫°o Gaussian kernel 2D t·ª´ c√¥ng th·ª©c to√°n h·ªçc.
    
    üî¢ C√îNG TH·ª®C:
        G(x,y) = (1/2œÄœÉ¬≤) * exp(-(x¬≤+y¬≤)/2œÉ¬≤)
    
    üéØ M·ª§C ƒê√çCH:
        T·∫°o ma tr·∫≠n Gaussian ƒë·ªÉ l√†m m·ªù ·∫£nh theo ph√¢n ph·ªëi chu·∫©n.
        Pixel ·ªü trung t√¢m c√≥ tr·ªçng s·ªë cao nh·∫•t, gi·∫£m d·∫ßn v·ªÅ c√°c c·∫°nh.
    
    üìä THAM S·ªê:
        size (int): K√≠ch th∆∞·ªõc kernel (3, 5, 7, 9, ...)
        sigma (float): ƒê·ªô l·ªách chu·∫©n - C√†ng l·ªõn = m·ªù c√†ng m·∫°nh
    
    ‚ú® T√çNH NƒÇNG:
        - T·ª± ƒë·ªông normalize t·ªïng = 1
        - Kernel ƒë·ªëi x·ª©ng qua t√¢m
        - Ph√π h·ª£p cho Gaussian Blur v√† Canny Edge Detection
    
    üí° V√ç D·ª§:
        >>> kernel = create_gaussian_kernel(5, 1.0)
        >>> kernel.shape  # (5, 5)
        >>> kernel.sum()  # ~1.0
    
    üìñ THAM KH·∫¢O:
        - Gonzalez & Woods: Digital Image Processing, Chapter 3
        - https://en.wikipedia.org/wiki/Gaussian_blur
    """
    # Validation
    if size < 3:
        raise ValueError(f"Kernel size ph·∫£i ‚â• 3, nh·∫≠n ƒë∆∞·ª£c: {size}")
    if size % 2 == 0:
        raise ValueError(f"Kernel size ph·∫£i l√† s·ªë l·∫ª, nh·∫≠n ƒë∆∞·ª£c: {size}")
    if sigma <= 0:
        raise ValueError(f"Sigma ph·∫£i > 0, nh·∫≠n ƒë∆∞·ª£c: {sigma}")
    
    kernel = np.zeros((size, size))
    center = size // 2
    
    # T√≠nh t·ªïng ƒë·ªÉ normalize
    sum_val = 0.0
    
    for i in range(size):
        for j in range(size):
            x = i - center
            y = j - center
            kernel[i, j] = np.exp(-(x**2 + y**2) / (2 * sigma**2))
            sum_val += kernel[i, j]
    
    # Normalize kernel
    kernel /= sum_val
    return kernel


def convolve2d(image: np.ndarray, kernel: np.ndarray) -> np.ndarray:
    """
    T·ª± implement Convolution 2D - Thao t√°c c∆° b·∫£n nh·∫•t trong x·ª≠ l√Ω ·∫£nh.
    
    üîÑ NGUY√äN L√ù:
        Tr∆∞·ª£t kernel qua t·ª´ng v·ªã tr√≠ tr√™n ·∫£nh, t√≠nh t·ªïng t√≠ch element-wise.
        Output[i,j] = Œ£ Œ£ Image[i+m,j+n] * Kernel[m,n]
    
    üéØ M·ª§C ƒê√çCH:
        - √Åp d·ª•ng filter (blur, sharpen, edge detection)
        - C∆° s·ªü cho h·∫ßu h·∫øt c√°c thu·∫≠t to√°n x·ª≠ l√Ω ·∫£nh
    
    üìä THAM S·ªê:
        image (np.ndarray): ·∫¢nh ƒë·∫ßu v√†o (H√óW ho·∫∑c H√óW√óC)
        kernel (np.ndarray): Ma tr·∫≠n filter (th∆∞·ªùng 3√ó3, 5√ó5, 7√ó7)
    
    ‚ú® T√çNH NƒÇNG:
        - T·ª± ƒë·ªông x·ª≠ l√Ω ·∫£nh RGB (convolution t·ª´ng channel ri√™ng)
        - Edge padding ƒë·ªÉ gi·ªØ nguy√™n k√≠ch th∆∞·ªõc output
        - Clipping v·ªÅ [0, 255] ƒë·ªÉ tr√°nh overflow
    
    ‚ö° HI·ªÜU SU·∫§T:
        - O(H √ó W √ó K¬≤) v·ªõi K l√† kernel size
        - C√≥ th·ªÉ t·ªëi ∆∞u b·∫±ng FFT cho kernel l·ªõn (ch∆∞a implement)
    
    üí° V√ç D·ª§:
        >>> blur_kernel = create_gaussian_kernel(5)
        >>> blurred = convolve2d(image, blur_kernel)
    """
    # Validation
    if image.size == 0:
        raise ValueError("·∫¢nh r·ªóng (empty image)")
    if kernel.shape[0] != kernel.shape[1]:
        raise ValueError(f"Kernel ph·∫£i l√† ma tr·∫≠n vu√¥ng, nh·∫≠n: {kernel.shape}")
    if kernel.shape[0] % 2 == 0:
        raise ValueError(f"Kernel size ph·∫£i l·∫ª, nh·∫≠n: {kernel.shape[0]}")
    
    if len(image.shape) == 3:
        # X·ª≠ l√Ω t·ª´ng channel ri√™ng
        result = np.zeros_like(image)
        for c in range(image.shape[2]):
            result[:, :, c] = convolve2d(image[:, :, c], kernel)
        return result
    
    # Padding ƒë·ªÉ gi·ªØ k√≠ch th∆∞·ªõc output
    pad = kernel.shape[0] // 2
    padded = np.pad(image, pad, mode='edge')
    
    h, w = image.shape
    kh, kw = kernel.shape
    result = np.zeros_like(image, dtype=np.float64)
    
    # Convolution v·ªõi t·ªëi ∆∞u
    # TODO: C√≥ th·ªÉ t·ªëi ∆∞u th√™m b·∫±ng vectorization ho·∫∑c scipy.signal.convolve2d
    for i in range(h):
        for j in range(w):
            region = padded[i:i+kh, j:j+kw]
            result[i, j] = np.sum(region * kernel)
    
    return np.clip(result, 0, 255).astype(np.uint8)


# Cache cho Gaussian kernels (tƒÉng hi·ªáu su·∫•t)
_gaussian_kernel_cache = {}

def custom_gaussian_blur(image: np.ndarray, ksize: int, sigma: float = None) -> np.ndarray:
    """
    üå´Ô∏è GAUSSIAN BLUR - L√†m m·ªù ·∫£nh theo ph√¢n ph·ªëi Gaussian
    
    üéØ M·ª§C ƒê√çCH:
        L√†m m·ªãn ·∫£nh ƒë·ªÉ:
        - Gi·∫£m nhi·ªÖu (noise reduction)
        - Chu·∫©n b·ªã cho edge detection
        - T·∫°o hi·ªáu ·ª©ng bokeh/depth-of-field
    
    üî¨ THU·∫¨T TO√ÅN:
        1. T·∫°o Gaussian kernel v·ªõi sigma cho tr∆∞·ªõc
        2. √Åp d·ª•ng convolution 2D l√™n ·∫£nh
        3. Normalize k·∫øt qu·∫£ v·ªÅ [0, 255]
    
    üìä THAM S·ªê:
        image (np.ndarray): ·∫¢nh ƒë·∫ßu v√†o (H√óW ho·∫∑c H√óW√ó3)
        ksize (int): K√≠ch th∆∞·ªõc kernel (3, 5, 7, 9, ...)
        sigma (float, optional): ƒê·ªô l·ªách chu·∫©n
            - None: t·ª± ƒë·ªông t√≠nh theo c√¥ng th·ª©c OpenCV
            - 0.5-1.0: m·ªù nh·∫π
            - 1.0-2.0: m·ªù v·ª´a
            - >2.0: m·ªù m·∫°nh
    
    ‚úÖ ∆ØU ƒêI·ªÇM so v·ªõi Average Blur:
        - Gi·ªØ bi√™n t·ªët h∆°n (tr·ªçng s·ªë gi·∫£m d·∫ßn t·ª´ t√¢m)
        - T·ª± nhi√™n h∆°n cho m·∫Øt ng∆∞·ªùi
        - √çt t·∫°o artifact
    
    ‚ö†Ô∏è CH√ö √ù:
        - Kernel size c√†ng l·ªõn ‚Üí ch·∫≠m h∆°n
        - Kh√¥ng ph√π h·ª£p cho nhi·ªÖu "mu·ªëi ti√™u" (d√πng Median thay th·∫ø)
    
    üí° ·ª®NG D·ª§NG:
        - Ti·ªÅn x·ª≠ l√Ω cho Canny Edge Detection
        - L√†m m·ªù background trong ch·ª•p ·∫£nh ch√¢n dung
        - Gi·∫£m nhi·ªÖu trong ·∫£nh y khoa
    
    üìñ THAM KH·∫¢O:
        - Gonzalez & Woods, Chapter 3.4: Smoothing Spatial Filters
    """
    if sigma is None:
        sigma = 0.3 * ((ksize - 1) * 0.5 - 1) + 0.8
    
    # S·ª≠ d·ª•ng cache ƒë·ªÉ tr√°nh t√≠nh l·∫°i kernel gi·ªëng nhau
    cache_key = (ksize, round(sigma, 3))
    if cache_key not in _gaussian_kernel_cache:
        _gaussian_kernel_cache[cache_key] = create_gaussian_kernel(ksize, sigma)
    kernel = _gaussian_kernel_cache[cache_key]
    
    return convolve2d(image, kernel)


def custom_median_filter(image: np.ndarray, ksize: int) -> np.ndarray:
    """
    üî¢ MEDIAN FILTER - L·ªçc trung v·ªã ƒë·ªÉ kh·ª≠ nhi·ªÖu
    
    üéØ M·ª§C ƒê√çCH:
        Lo·∫°i b·ªè nhi·ªÖu "mu·ªëi ti√™u" (salt-and-pepper noise) hi·ªáu qu·∫£:
        - Gi·ªØ nguy√™n bi√™n s·∫Øc n√©t
        - Kh√¥ng l√†m m·ªù ·∫£nh nh∆∞ Gaussian
        - Thay pixel b·∫±ng gi√° tr·ªã median c·ªßa v√πng l√¢n c·∫≠n
    
    üî¨ THU·∫¨T TO√ÅN:
        1. Duy·ªát qua t·ª´ng pixel
        2. L·∫•y c·ª≠a s·ªï ksize√óksize xung quanh
        3. S·∫Øp x·∫øp c√°c gi√° tr·ªã v√† l·∫•y median
        4. Thay th·∫ø pixel trung t√¢m = median
    
    üìä THAM S·ªê:
        image (np.ndarray): ·∫¢nh ƒë·∫ßu v√†o
        ksize (int): K√≠ch th∆∞·ªõc c·ª≠a s·ªï (3, 5, 7)
            - 3: nhanh, kh·ª≠ nhi·ªÖu nh·∫π
            - 5: c√¢n b·∫±ng t·ªëc ƒë·ªô v√† hi·ªáu qu·∫£
            - 7+: ch·∫≠m, kh·ª≠ nhi·ªÖu m·∫°nh
    
    ‚úÖ ∆ØU ƒêI·ªÇM:
        - R·∫•t hi·ªáu qu·∫£ v·ªõi nhi·ªÖu mu·ªëi ti√™u
        - Gi·ªØ bi√™n t·ªët (non-linear filter)
        - Kh√¥ng t·∫°o blur nh∆∞ Gaussian
    
    ‚ùå NH∆Ø·ª¢C ƒêI·ªÇM:
        - Ch·∫≠m h∆°n linear filters (O(n log n) do sorting)
        - C√≥ th·ªÉ l√†m m·∫•t chi ti·∫øt nh·ªè
        - Kh√¥ng hi·ªáu qu·∫£ v·ªõi nhi·ªÖu Gaussian
    
    üí° ·ª®NG D·ª§NG:
        - Kh·ª≠ nhi·ªÖu trong ·∫£nh scan, photocopy
        - X·ª≠ l√Ω ·∫£nh v·ªá tinh
        - Ti·ªÅn x·ª≠ l√Ω cho OCR
    
    üî¨ SO S√ÅNH:
        vs Gaussian Blur: Gi·ªØ bi√™n t·ªët h∆°n
        vs Mean Filter: √çt nh·∫°y c·∫£m v·ªõi outliers
    """
    if len(image.shape) == 3:
        result = np.zeros_like(image)
        for c in range(image.shape[2]):
            result[:, :, c] = custom_median_filter(image[:, :, c], ksize)
        return result
    
    pad = ksize // 2
    padded = np.pad(image, pad, mode='edge')
    
    h, w = image.shape
    result = np.zeros_like(image)
    
    for i in range(h):
        for j in range(w):
            region = padded[i:i+ksize, j:j+ksize]
            result[i, j] = np.median(region)
    
    return result.astype(np.uint8)


# ==================== EDGE DETECTION ====================

def custom_sobel_operator(image: np.ndarray, direction: str = 'both') -> np.ndarray:
    """
    üîç SOBEL OPERATOR - Ph√°t hi·ªán bi√™n b·∫±ng gradient
    
    üéØ M·ª§C ƒê√çCH:
        T√¨m bi√™n trong ·∫£nh b·∫±ng c√°ch t√≠nh gradient theo h∆∞·ªõng X v√† Y:
        - Ph√°t hi·ªán thay ƒë·ªïi c∆∞·ªùng ƒë·ªô s√°ng ƒë·ªôt ng·ªôt
        - X√°c ƒë·ªãnh h∆∞·ªõng v√† ƒë·ªô m·∫°nh c·ªßa bi√™n
    
    üî¨ THU·∫¨T TO√ÅN:
        1. Chuy·ªÉn ·∫£nh v·ªÅ grayscale
        2. √Åp d·ª•ng Sobel kernels:
            Gx = [[-1, 0, 1],     Gy = [[-1, -2, -1],
                  [-2, 0, 2],           [ 0,  0,  0],
                  [-1, 0, 1]]           [ 1,  2,  1]]
        3. T√≠nh magnitude: G = ‚àö(Gx¬≤ + Gy¬≤)
    
    üìä THAM S·ªê:
        image (np.ndarray): ·∫¢nh ƒë·∫ßu v√†o
        direction (str): H∆∞·ªõng gradient
            - 'x': Ph√°t hi·ªán bi√™n d·ªçc (vertical edges)
            - 'y': Ph√°t hi·ªán bi√™n ngang (horizontal edges)
            - 'both': Magnitude t·ªïng h·ª£p (m·∫∑c ƒë·ªãnh)
    
    üî¢ C√îNG TH·ª®C:
        - Gx: Gradient theo chi·ªÅu ngang (thay ƒë·ªïi tr√°i-ph·∫£i)
        - Gy: Gradient theo chi·ªÅu d·ªçc (thay ƒë·ªïi tr√™n-d∆∞·ªõi)
        - Magnitude: ‚àö(Gx¬≤ + Gy¬≤)
        - Direction: arctan(Gy/Gx)
    
    ‚úÖ ∆ØU ƒêI·ªÇM:
        - ƒê∆°n gi·∫£n, nhanh
        - Gi·∫£m nhi·ªÖu t·ªët (c√≥ smoothing)
        - Ph√°t hi·ªán c·∫£ h∆∞·ªõng bi√™n
    
    ‚ùå NH∆Ø·ª¢C ƒêI·ªÇM:
        - Nh·∫°y c·∫£m v·ªõi nhi·ªÖu
        - Bi√™n d√†y (thick edges)
        - Kh√¥ng optimal nh∆∞ Canny
    
    üí° ·ª®NG D·ª§NG:
        - Ti·ªÅn x·ª≠ l√Ω cho object detection
        - T√¨m ƒë∆∞·ªùng vi·ªÅn trong CAD
        - Ph√¢n t√≠ch k·∫øt c·∫•u (texture)
    
    üìñ THAM KH·∫¢O:
        - Sobel, I. (1968): "An Isotropic 3√ó3 Image Gradient Operator"
    """
    # Chuy·ªÉn sang grayscale n·∫øu l√† ·∫£nh m√†u
    if len(image.shape) == 3:
        gray = rgb_to_grayscale(image)
    else:
        gray = image.copy()
    
    # Sobel kernels
    sobel_x = np.array([[-1, 0, 1],
                        [-2, 0, 2],
                        [-1, 0, 1]], dtype=np.float64)
    
    sobel_y = np.array([[-1, -2, -1],
                        [0,  0,  0],
                        [1,  2,  1]], dtype=np.float64)
    
    # √Åp d·ª•ng convolution
    if direction == 'x':
        gradient = convolve2d(gray, sobel_x)
    elif direction == 'y':
        gradient = convolve2d(gray, sobel_y)
    else:  # both - magnitude
        gx = convolve2d(gray.astype(np.float64), sobel_x)
        gy = convolve2d(gray.astype(np.float64), sobel_y)
        gradient = np.sqrt(gx**2 + gy**2)
    
    # Normalize v·ªÅ [0, 255]
    gradient = np.clip(gradient, 0, 255).astype(np.uint8)
    
    # Chuy·ªÉn v·ªÅ 3 channels n·∫øu c·∫ßn
    if len(image.shape) == 3:
        gradient = np.stack([gradient] * 3, axis=-1)
    
    return gradient


def non_maximum_suppression(magnitude: np.ndarray, angle: np.ndarray) -> np.ndarray:
    """
    Non-maximum suppression cho Canny edge detection.
    """
    h, w = magnitude.shape
    result = np.zeros_like(magnitude)
    
    # L√†m tr√≤n g√≥c v·ªÅ 4 h∆∞·ªõng: 0, 45, 90, 135
    angle = np.rad2deg(angle) % 180
    
    for i in range(1, h-1):
        for j in range(1, w-1):
            q = 255
            r = 255
            
            # X√°c ƒë·ªãnh 2 pixel l√°ng gi·ªÅng theo h∆∞·ªõng gradient
            if (0 <= angle[i,j] < 22.5) or (157.5 <= angle[i,j] <= 180):
                q = magnitude[i, j+1]
                r = magnitude[i, j-1]
            elif 22.5 <= angle[i,j] < 67.5:
                q = magnitude[i+1, j-1]
                r = magnitude[i-1, j+1]
            elif 67.5 <= angle[i,j] < 112.5:
                q = magnitude[i+1, j]
                r = magnitude[i-1, j]
            elif 112.5 <= angle[i,j] < 157.5:
                q = magnitude[i-1, j-1]
                r = magnitude[i+1, j+1]
            
            # Gi·ªØ l·∫°i n·∫øu l√† c·ª±c ƒë·∫°i c·ª•c b·ªô
            if magnitude[i,j] >= q and magnitude[i,j] >= r:
                result[i,j] = magnitude[i,j]
            else:
                result[i,j] = 0
    
    return result


def double_threshold(image: np.ndarray, low_ratio: float = 0.05, high_ratio: float = 0.15) -> tuple:
    """
    Double threshold cho Canny edge detection.
    """
    high_threshold = image.max() * high_ratio
    low_threshold = high_threshold * low_ratio
    
    strong = 255
    weak = 75
    
    result = np.zeros_like(image)
    
    strong_i, strong_j = np.where(image >= high_threshold)
    weak_i, weak_j = np.where((image >= low_threshold) & (image < high_threshold))
    
    result[strong_i, strong_j] = strong
    result[weak_i, weak_j] = weak
    
    return result, weak, strong


def edge_tracking_by_hysteresis(image: np.ndarray, weak: int, strong: int) -> np.ndarray:
    """
    Edge tracking b·∫±ng hysteresis cho Canny.
    """
    h, w = image.shape
    
    for i in range(1, h-1):
        for j in range(1, w-1):
            if image[i, j] == weak:
                # Ki·ªÉm tra 8 l√°ng gi·ªÅng
                if ((image[i+1, j-1] == strong) or (image[i+1, j] == strong) or 
                    (image[i+1, j+1] == strong) or (image[i, j-1] == strong) or 
                    (image[i, j+1] == strong) or (image[i-1, j-1] == strong) or 
                    (image[i-1, j] == strong) or (image[i-1, j+1] == strong)):
                    image[i, j] = strong
                else:
                    image[i, j] = 0
    
    return image


def custom_canny_edge(image: np.ndarray, low_threshold: int = 50, high_threshold: int = 150) -> np.ndarray:
    """
    ‚≠ê CANNY EDGE DETECTION - Thu·∫≠t to√°n ph√°t hi·ªán bi√™n t·ªëi ∆∞u
    
    üèÜ ƒê·∫∂C ƒêI·ªÇM:
        Thu·∫≠t to√°n ph√°t hi·ªán bi√™n T·ªêT NH·∫§T ƒë∆∞·ª£c ph√°t tri·ªÉn b·ªüi John Canny (1986):
        - Bi√™n m·ªèng (single-pixel)
        - √çt nhi·ªÖu gi·∫£ (false edges)
        - Ch√≠nh x√°c cao
    
    üî¨ 5 B∆Ø·ªöC TH·ª∞C HI·ªÜN:
        
        B∆Ø·ªöC 1Ô∏è‚É£: NOISE REDUCTION (Gi·∫£m nhi·ªÖu)
            ‚Üí √Åp d·ª•ng Gaussian Blur (5√ó5, œÉ=1.4)
            ‚Üí L√Ω do: Canny r·∫•t nh·∫°y nhi·ªÖu
        
        B∆Ø·ªöC 2Ô∏è‚É£: GRADIENT CALCULATION (T√≠nh gradient)
            ‚Üí Sobel operators: Gx, Gy
            ‚Üí Magnitude: G = ‚àö(Gx¬≤ + Gy¬≤)
            ‚Üí Direction: Œ∏ = arctan(Gy/Gx)
        
        B∆Ø·ªöC 3Ô∏è‚É£: NON-MAXIMUM SUPPRESSION (L√†m m·ªèng bi√™n)
            ‚Üí Gi·ªØ l·∫°i pixel c·ª±c ƒë·∫°i theo h∆∞·ªõng gradient
            ‚Üí Lo·∫°i b·ªè pixel kh√¥ng ph·∫£i bi√™n ch√≠nh
            ‚Üí K·∫øt qu·∫£: bi√™n d√†y 1 pixel
        
        B∆Ø·ªöC 4Ô∏è‚É£: DOUBLE THRESHOLD (Ng∆∞·ª°ng k√©p)
            ‚Üí Strong edges: G > high_threshold
            ‚Üí Weak edges: low_threshold < G < high_threshold
            ‚Üí Non-edges: G < low_threshold
        
        B∆Ø·ªöC 5Ô∏è‚É£: EDGE TRACKING BY HYSTERESIS (Theo d√µi bi√™n)
            ‚Üí Gi·ªØ weak edges n·∫øu k·∫øt n·ªëi v·ªõi strong edges
            ‚Üí Lo·∫°i b·ªè weak edges ƒë·ª©ng ri√™ng
            ‚Üí K·∫øt qu·∫£: bi√™n li√™n t·ª•c
    
    üìä THAM S·ªê:
        image (np.ndarray): ·∫¢nh ƒë·∫ßu v√†o
        low_threshold (int): Ng∆∞·ª°ng th·∫•p (50-100)
            - Th·∫•p: nhi·ªÅu bi√™n, nhi·ªÅu nhi·ªÖu
            - Cao: √≠t bi√™n, m·∫•t chi ti·∫øt
        high_threshold (int): Ng∆∞·ª°ng cao (150-200)
            - T·ª∑ l·ªá khuy·∫øn ngh·ªã: high = 2-3 √ó low
    
    ‚öôÔ∏è C√ÅCH CH·ªåN THRESHOLD:
        - ·∫¢nh nhi·ªÖu nhi·ªÅu: TƒÉng c·∫£ 2 ng∆∞·ª°ng
        - Mu·ªën nhi·ªÅu chi ti·∫øt: Gi·∫£m c·∫£ 2
        - T·ª∑ l·ªá high/low = 2:1 ho·∫∑c 3:1
    
    ‚úÖ ∆ØU ƒêI·ªÇM:
        - Bi√™n m·ªèng, ch√≠nh x√°c nh·∫•t
        - √çt nhi·ªÖu gi·∫£ (false positives)
        - Bi√™n li√™n t·ª•c
    
    ‚ùå NH∆Ø·ª¢C ƒêI·ªÇM:
        - Ch·∫≠m (5 b∆∞·ªõc x·ª≠ l√Ω)
        - C·∫ßn ƒëi·ªÅu ch·ªânh threshold
        - Kh√¥ng ph√°t hi·ªán g√≥c t·ªët
    
    üí° ·ª®NG D·ª§NG:
        - Computer Vision c∆° b·∫£n
        - Lane detection (xe t·ª± l√°i)
        - Medical imaging
        - Object recognition
    
    üìñ THAM KH·∫¢O:
        - Canny, J. (1986): "A Computational Approach to Edge Detection"
        - IEEE TPAMI, Vol. PAMI-8, No. 6
    
    üéØ T·∫†I SAO CANNY T·ªêT NH·∫§T?
        1. Good detection: T√¨m ƒë√∫ng bi√™n th·∫≠t
        2. Good localization: Bi√™n ƒë√∫ng v·ªã tr√≠
        3. Single response: M·ªói bi√™n ch·ªâ 1 pixel
    """
    # Chuy·ªÉn sang grayscale
    if len(image.shape) == 3:
        gray = rgb_to_grayscale(image)
    else:
        gray = image.copy()
    
    # B∆∞·ªõc 1: Gaussian blur
    blurred = custom_gaussian_blur(gray, 5, 1.4)
    
    # B∆∞·ªõc 2: T√≠nh gradient v·ªõi Sobel
    sobel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=np.float64)
    sobel_y = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=np.float64)
    
    gx = convolve2d(blurred.astype(np.float64), sobel_x)
    gy = convolve2d(blurred.astype(np.float64), sobel_y)
    
    magnitude = np.sqrt(gx**2 + gy**2)
    angle = np.arctan2(gy, gx)
    
    # B∆∞·ªõc 3: Non-maximum suppression
    suppressed = non_maximum_suppression(magnitude, angle)
    
    # B∆∞·ªõc 4 & 5: Double threshold v√† hysteresis
    thresholded, weak, strong = double_threshold(suppressed, low_threshold/255, high_threshold/255)
    edges = edge_tracking_by_hysteresis(thresholded.copy(), weak, strong)
    
    # Chuy·ªÉn v·ªÅ 3 channels
    if len(image.shape) == 3:
        edges = np.stack([edges] * 3, axis=-1)
    
    return edges.astype(np.uint8)


# ==================== THRESHOLDING ====================

def custom_global_threshold(image: np.ndarray, threshold: int) -> np.ndarray:
    """
    T·ª± implement Global Thresholding.
    """
    if len(image.shape) == 3:
        gray = rgb_to_grayscale(image)
    else:
        gray = image.copy()
    
    result = np.where(gray > threshold, 255, 0).astype(np.uint8)
    
    if len(image.shape) == 3:
        result = np.stack([result] * 3, axis=-1)
    
    return result


def custom_otsu_threshold(image: np.ndarray) -> np.ndarray:
    """
    üéØ OTSU'S THRESHOLDING - T·ª± ƒë·ªông t√¨m ng∆∞·ª°ng t·ªëi ∆∞u
    
    üèÜ ƒê·∫∂C ƒêI·ªÇM:
        Thu·∫≠t to√°n t·ª± ƒë·ªông t√¨m ng∆∞·ª°ng ph√¢n ƒëo·∫°n T·ªêI ∆ØU (Nobuyuki Otsu, 1979):
        - Kh√¥ng c·∫ßn tham s·ªë ƒë·∫ßu v√†o
        - T·ªëi ∆∞u h√≥a to√°n h·ªçc
        - Ph√π h·ª£p cho ·∫£nh bimodal histogram
    
    üî¨ THU·∫¨T TO√ÅN:
        
        1Ô∏è‚É£ T√çNH HISTOGRAM:
            ‚Üí ƒê·∫øm s·ªë pixel cho m·ªói m·ª©c x√°m [0-255]
            ‚Üí Normalize th√†nh ph√¢n ph·ªëi x√°c su·∫•t
        
        2Ô∏è‚É£ TH·ª¨ T·∫§T C·∫¢ NG∆Ø·ª†NG (t = 1‚Üí255):
            V·ªõi m·ªói ng∆∞·ª°ng t:
            ‚Üí Chia ·∫£nh th√†nh 2 class:
                ‚Ä¢ Class 0 (background): [0, t)
                ‚Ä¢ Class 1 (foreground): [t, 255]
        
        3Ô∏è‚É£ T√çNH BETWEEN-CLASS VARIANCE:
            œÉ¬≤ ô(t) = w‚ÇÄ(t) √ó w‚ÇÅ(t) √ó [Œº‚ÇÄ(t) - Œº‚ÇÅ(t)]¬≤
            
            Trong ƒë√≥:
            ‚Ä¢ w‚ÇÄ, w‚ÇÅ: X√°c su·∫•t c·ªßa class 0, 1
            ‚Ä¢ Œº‚ÇÄ, Œº‚ÇÅ: Mean c·ªßa class 0, 1
        
        4Ô∏è‚É£ CH·ªåN NG∆Ø·ª†NG T·ªêI ∆ØU:
            t* = argmax œÉ¬≤ ô(t)
            ‚Üí Ng∆∞·ª°ng l√†m 2 class t√°ch bi·ªát nh·∫•t
    
    üìä THAM S·ªê:
        image (np.ndarray): ·∫¢nh ƒë·∫ßu v√†o
    
    üî¢ L√ù THUY·∫æT:
        - Between-class variance: ƒêo ƒë·ªô t√°ch bi·ªát gi·ªØa 2 class
        - Variance cao = 2 class ph√¢n bi·ªát r√µ
        - T∆∞∆°ng ƒë∆∞∆°ng minimize within-class variance
    
    ‚úÖ ∆ØU ƒêI·ªÇM:
        - HO√ÄN TO√ÄN T·ª∞ ƒê·ªòNG (kh√¥ng c·∫ßn tham s·ªë)
        - T·ªëi ∆∞u to√°n h·ªçc
        - Nhanh (O(256 √ó n))
        - Reproducible
    
    ‚ùå NH∆Ø·ª¢C ƒêI·ªÇM:
        - Ch·ªâ ph√π h·ª£p v·ªõi bimodal histogram
        - Th·∫•t b·∫°i n·∫øu object/background kh√¥ng c√¢n b·∫±ng
        - Nh·∫°y c·∫£m v·ªõi nhi·ªÖu
    
    üí° KHI N√ÄO D√ôNG OTSU:
        ‚úÖ Histogram c√≥ 2 ƒë·ªânh r√µ r√†ng
        ‚úÖ Object v√† background c√≥ k√≠ch th∆∞·ªõc t∆∞∆°ng ƒë∆∞∆°ng
        ‚úÖ C·∫ßn ph√¢n ƒëo·∫°n t·ª± ƒë·ªông
        ‚ùå Histogram ph·ª©c t·∫°p (multimodal)
        ‚ùå √Ånh s√°ng kh√¥ng ƒë·ªÅu (d√πng Adaptive thay th·∫ø)
    
    üéØ ·ª®NG D·ª§NG:
        - Document scanning (t√°ch ch·ªØ kh·ªèi n·ªÅn)
        - Medical imaging (ph√¢n ƒëo·∫°n t·∫ø b√†o)
        - Quality inspection (ph√°t hi·ªán l·ªói)
        - Foreground/background separation
    
    üìñ THAM KH·∫¢O:
        - Otsu, N. (1979): "A Threshold Selection Method from Gray-Level Histograms"
        - IEEE Trans. Systems, Man, and Cybernetics, Vol. 9, No. 1
        - Citation: 35,000+ (thu·∫≠t to√°n kinh ƒëi·ªÉn!)
    
    üî¨ SO S√ÅNH:
        vs Global Threshold: T·ª± ƒë·ªông, kh√¥ng c·∫ßn ƒëo√°n ng∆∞·ª°ng
        vs Adaptive: Nhanh h∆°n, nh∆∞ng k√©m linh ho·∫°t
    """
    if len(image.shape) == 3:
        gray = rgb_to_grayscale(image)
    else:
        gray = image.copy()
    
    # T√≠nh histogram
    hist, _ = np.histogram(gray.flatten(), bins=256, range=[0, 256])
    hist = hist.astype(float)
    
    # Normalize histogram
    hist /= hist.sum()
    
    # T√¨m ng∆∞·ª°ng t·ªëi ∆∞u
    max_variance = 0
    optimal_threshold = 0
    
    for t in range(1, 256):
        # X√°c su·∫•t class 0 (background)
        w0 = hist[:t].sum()
        if w0 == 0:
            continue
        
        # X√°c su·∫•t class 1 (foreground)
        w1 = hist[t:].sum()
        if w1 == 0:
            break
        
        # Mean c·ªßa class 0
        mu0 = (np.arange(t) * hist[:t]).sum() / w0
        
        # Mean c·ªßa class 1
        mu1 = (np.arange(t, 256) * hist[t:]).sum() / w1
        
        # Between-class variance
        variance = w0 * w1 * (mu0 - mu1) ** 2
        
        if variance > max_variance:
            max_variance = variance
            optimal_threshold = t
    
    # √Åp d·ª•ng threshold
    result = np.where(gray > optimal_threshold, 255, 0).astype(np.uint8)
    
    if len(image.shape) == 3:
        result = np.stack([result] * 3, axis=-1)
    
    return result


def custom_adaptive_threshold(image: np.ndarray, block_size: int = 11, C: int = 2, method: str = 'mean') -> np.ndarray:
    """
    T·ª± implement Adaptive Thresholding.
    """
    if len(image.shape) == 3:
        gray = rgb_to_grayscale(image)
    else:
        gray = image.copy()
    
    h, w = gray.shape
    result = np.zeros_like(gray)
    pad = block_size // 2
    padded = np.pad(gray, pad, mode='edge')
    
    for i in range(h):
        for j in range(w):
            region = padded[i:i+block_size, j:j+block_size]
            
            if method == 'mean':
                threshold = region.mean() - C
            else:  # gaussian
                # T·∫°o gaussian weight
                kernel = create_gaussian_kernel(block_size, block_size / 6)
                threshold = np.sum(region * kernel) / kernel.sum() - C
            
            result[i, j] = 255 if gray[i, j] > threshold else 0
    
    if len(image.shape) == 3:
        result = np.stack([result] * 3, axis=-1)
    
    return result.astype(np.uint8)


# ==================== MORPHOLOGICAL OPERATIONS ====================

def custom_erosion(image: np.ndarray, kernel_size: int) -> np.ndarray:
    """
    ‚ö´ EROSION - X√≥i m√≤n v·∫≠t th·ªÉ (Morphological Operation)
    
    üéØ M·ª§C ƒê√çCH:
        "X√≥i" v·∫≠t th·ªÉ tr·∫Øng, l√†m m·∫£nh ƒëi:
        - Lo·∫°i b·ªè nhi·ªÖu nh·ªè b√™n ngo√†i object
        - T√°ch c√°c object d√≠nh nhau
        - L√†m m·ªèng bi√™n
    
    üî¨ THU·∫¨T TO√ÅN:
        1. Tr∆∞·ª£t kernel qua t·ª´ng pixel
        2. L·∫•y gi√° tr·ªã MINIMUM trong c·ª≠a s·ªï
        3. G√°n cho pixel trung t√¢m
        
        ‚Üí K·∫øt qu·∫£: Pixel tr·∫Øng ch·ªâ gi·ªØ l·∫°i n·∫øu T·∫§T C·∫¢ l√°ng gi·ªÅng ƒë·ªÅu tr·∫Øng
    
    üìä THAM S·ªê:
        image (np.ndarray): ·∫¢nh binary (ƒëen/tr·∫Øng)
        kernel_size (int): K√≠ch th∆∞·ªõc kernel (3, 5, 7)
    
    ‚úÖ HI·ªÜU QU·∫¢:
        - Lo·∫°i b·ªè nhi·ªÖu tr·∫Øng nh·ªè
        - Ng·∫Øt k·∫øt n·ªëi y·∫øu
        - L√†m m·∫£nh boundary
    
    üí° ·ª®NG D·ª§NG:
        - Kh·ª≠ nhi·ªÖu trong ·∫£nh binary
        - T√°ch ƒë·ªëi t∆∞·ª£ng d√≠nh nhau
        - Skeleton extraction (k·∫øt h·ª£p nhi·ªÅu l·∫ßn)
    
    üîó K·∫æT H·ª¢P:
        Erosion + Dilation = Opening (lo·∫°i nhi·ªÖu ngo√†i)
    """
    if len(image.shape) == 3:
        gray = rgb_to_grayscale(image)
    else:
        gray = image.copy()
    
    pad = kernel_size // 2
    padded = np.pad(gray, pad, mode='edge')
    
    h, w = gray.shape
    result = np.zeros_like(gray)
    
    for i in range(h):
        for j in range(w):
            region = padded[i:i+kernel_size, j:j+kernel_size]
            result[i, j] = region.min()
    
    if len(image.shape) == 3:
        result = np.stack([result] * 3, axis=-1)
    
    return result.astype(np.uint8)


def custom_dilation(image: np.ndarray, kernel_size: int) -> np.ndarray:
    """
    ‚ö™ DILATION - Gi√£n n·ªü v·∫≠t th·ªÉ (Morphological Operation)
    
    üéØ M·ª§C ƒê√çCH:
        "Ph√¨nh" v·∫≠t th·ªÉ tr·∫Øng, l√†m d√†y l√™n:
        - L·∫•p c√°c l·ªó nh·ªè b√™n trong object
        - N·ªëi c√°c ph·∫ßn g·∫ßn nhau
        - L√†m d√†y bi√™n
    
    üî¨ THU·∫¨T TO√ÅN:
        1. Tr∆∞·ª£t kernel qua t·ª´ng pixel
        2. L·∫•y gi√° tr·ªã MAXIMUM trong c·ª≠a s·ªï
        3. G√°n cho pixel trung t√¢m
        
        ‚Üí K·∫øt qu·∫£: Pixel tr·∫Øng n·∫øu C√ì √çT NH·∫§T 1 l√°ng gi·ªÅng tr·∫Øng
    
    üìä THAM S·ªê:
        image (np.ndarray): ·∫¢nh binary
        kernel_size (int): K√≠ch th∆∞·ªõc kernel
    
    ‚úÖ HI·ªÜU QU·∫¢:
        - L·∫•p l·ªó nh·ªè
        - N·ªëi k·∫øt n·ªëi y·∫øu
        - L√†m d√†y boundary
    
    üí° ·ª®NG D·ª§NG:
        - N·ªëi vƒÉn b·∫£n b·ªã ƒë·ª©t
        - L·∫•p l·ªó trong object
        - T·∫°o buffer zone
    
    üîó K·∫æT H·ª¢P:
        Dilation + Erosion = Closing (l·∫•p l·ªó trong)
    
    üî¨ NG∆Ø·ª¢C L·∫†I V·ªöI:
        Erosion (x√≥i m√≤n) ‚Üî Dilation (gi√£n n·ªü)
    """
    if len(image.shape) == 3:
        gray = rgb_to_grayscale(image)
    else:
        gray = image.copy()
    
    pad = kernel_size // 2
    padded = np.pad(gray, pad, mode='edge')
    
    h, w = gray.shape
    result = np.zeros_like(gray)
    
    for i in range(h):
        for j in range(w):
            region = padded[i:i+kernel_size, j:j+kernel_size]
            result[i, j] = region.max()
    
    if len(image.shape) == 3:
        result = np.stack([result] * 3, axis=-1)
    
    return result.astype(np.uint8)


def custom_opening(image: np.ndarray, kernel_size: int) -> np.ndarray:
    """
    üîì OPENING - X√≥a nhi·ªÖu b√™n ngo√†i (Erosion ‚Üí Dilation)
    
    üéØ M·ª§C ƒê√çCH:
        Lo·∫°i b·ªè nhi·ªÖu nh·ªè B√äN NGO√ÄI object m√† KH√îNG thay ƒë·ªïi k√≠ch th∆∞·ªõc:
        - X√≥a c√°c ƒëi·ªÉm tr·∫Øng nh·ªè l·∫ª
        - L√†m m·ªãn bi√™n ngo√†i
        - Ng·∫Øt k·∫øt n·ªëi m·∫£nh
    
    üî¨ QUY TR√åNH:
        1. Erosion: X√≥i m√≤n ‚Üí Nhi·ªÖu nh·ªè bi·∫øn m·∫•t
        2. Dilation: Gi√£n n·ªü ‚Üí Ph·ª•c h·ªìi k√≠ch th∆∞·ªõc ban ƒë·∫ßu
        
        ‚Üí Nhi·ªÖu nh·ªè kh√¥ng ƒë∆∞·ª£c ph·ª•c h·ªìi l·∫°i!
    
    üí° ·ª®NG D·ª§NG:
        - Kh·ª≠ nhi·ªÖu trong OCR
        - L√†m s·∫°ch ·∫£nh scan
        - T√°ch object ri√™ng bi·ªát
    """
    eroded = custom_erosion(image, kernel_size)
    opened = custom_dilation(eroded, kernel_size)
    return opened


def custom_closing(image: np.ndarray, kernel_size: int) -> np.ndarray:
    """
    T·ª± implement Closing = Dilation -> Erosion.
    L·∫•p ƒë·∫ßy c√°c l·ªó nh·ªè.
    """
    dilated = custom_dilation(image, kernel_size)
    closed = custom_erosion(dilated, kernel_size)
    return closed


# ==================== HISTOGRAM EQUALIZATION ====================

def custom_histogram_equalization(image: np.ndarray) -> np.ndarray:
    """
    üìä HISTOGRAM EQUALIZATION - C√¢n b·∫±ng histogram ƒë·ªÉ tƒÉng t∆∞∆°ng ph·∫£n
    
    üéØ M·ª§C ƒê√çCH:
        Ph√¢n b·ªë l·∫°i gi√° tr·ªã pixel ƒë·ªÉ:
        - TƒÉng ƒë·ªô t∆∞∆°ng ph·∫£n t·ª± ƒë·ªông
        - S·ª≠ d·ª•ng ƒë·∫ßy ƒë·ªß d·∫£i [0-255]
        - L√†m n·ªïi chi ti·∫øt trong ·∫£nh t·ªëi/s√°ng
    
    üî¨ THU·∫¨T TO√ÅN:
        
        1Ô∏è‚É£ T√çNH HISTOGRAM:
            h(i) = s·ªë pixel c√≥ gi√° tr·ªã i
        
        2Ô∏è‚É£ T√çNH CDF (Cumulative Distribution Function):
            CDF(i) = Œ£ h(j) for j=0 to i
        
        3Ô∏è‚É£ NORMALIZE CDF:
            CDF_norm(i) = 255 √ó CDF(i) / CDF(255)
        
        4Ô∏è‚É£ MAP PIXEL M·ªöI:
            output[x,y] = CDF_norm[input[x,y]]
    
    üìä THAM S·ªê:
        image (np.ndarray): ·∫¢nh ƒë·∫ßu v√†o
    
    üî¢ C√îNG TH·ª®C:
        s = T(r) = (L-1) √ó Œ£ p(r‚±º)
        V·ªõi:
        - r: gi√° tr·ªã pixel g·ªëc
        - s: gi√° tr·ªã pixel m·ªõi
        - L: s·ªë m·ª©c x√°m (256)
        - p(r): x√°c su·∫•t c·ªßa r
    
    ‚úÖ ∆ØU ƒêI·ªÇM:
        - Ho√†n to√†n t·ª± ƒë·ªông
        - TƒÉng contrast hi·ªáu qu·∫£
        - Ph√π h·ª£p v·ªõi ·∫£nh t·ªëi/s√°ng qu√°
    
    ‚ùå NH∆Ø·ª¢C ƒêI·ªÇM:
        - C√≥ th·ªÉ tƒÉng nhi·ªÖu
        - Kh√¥ng ph√π h·ª£p v·ªõi ·∫£nh contrast t·ªët
        - Hi·ªáu ·ª©ng "kh√¥ng t·ª± nhi√™n" v·ªõi ·∫£nh m√†u
    
    üí° ·ª®NG D·ª§NG:
        - C·∫£i thi·ªán ·∫£nh y khoa (X-ray, MRI)
        - X·ª≠ l√Ω ·∫£nh v·ªá tinh
        - TƒÉng c∆∞·ªùng ·∫£nh t·ªëi (underexposed)
        - Computer vision preprocessing
    
    üéØ KHI N√ÄO D√ôNG:
        ‚úÖ ·∫¢nh t·ªëi ho·∫∑c s√°ng qu√°
        ‚úÖ Histogram t·∫≠p trung 1 v√πng h·∫πp
        ‚úÖ C·∫ßn tƒÉng contrast t·ª± ƒë·ªông
        ‚ùå ·∫¢nh ƒë√£ c√≥ contrast t·ªët
        ‚ùå C·∫ßn gi·ªØ tone m√†u t·ª± nhi√™n
    
    üìñ THAM KH·∫¢O:
        - Gonzalez & Woods, Chapter 3.3: Histogram Processing
    """
    if len(image.shape) == 3:
        # X·ª≠ l√Ω t·ª´ng channel
        result = np.zeros_like(image)
        for c in range(3):
            result[:, :, c] = custom_histogram_equalization(image[:, :, c])
        return result
    
    # T√≠nh histogram
    hist, _ = np.histogram(image.flatten(), bins=256, range=[0, 256])
    
    # T√≠nh CDF (Cumulative Distribution Function)
    cdf = hist.cumsum()
    
    # Normalize CDF v·ªÅ [0, 255]
    cdf_normalized = 255 * cdf / cdf[-1]
    
    # Map gi√° tr·ªã pixel c≈© sang gi√° tr·ªã m·ªõi
    result = np.interp(image.flatten(), np.arange(256), cdf_normalized)
    result = result.reshape(image.shape).astype(np.uint8)
    
    return result


# ==================== SHARPEN ====================

def custom_sharpen(image: np.ndarray) -> np.ndarray:
    """
    ‚ú® SHARPENING - L√†m s·∫Øc n√©t ·∫£nh b·∫±ng Laplacian kernel
    
    üéØ M·ª§C ƒê√çCH:
        TƒÉng c∆∞·ªùng bi√™n v√† chi ti·∫øt:
        - L√†m n·ªïi b·∫≠t ƒë∆∞·ªùng vi·ªÅn
        - TƒÉng ƒë·ªô s·∫Øc n√©t
        - L√†m r√µ texture
    
    üî¨ THU·∫¨T TO√ÅN:
        S·ª≠ d·ª•ng Laplacian kernel (high-pass filter):
        
        Kernel = [[-1, -1, -1],
                  [-1,  9, -1],
                  [-1, -1, -1]]
        
        Nguy√™n l√Ω:
        - Ph√°t hi·ªán bi·∫øn ƒë·ªïi b·∫≠c 2 (‚àá¬≤f)
        - C·ªông bi√™n v√†o ·∫£nh g·ªëc
        - L√†m n·ªïi chi ti·∫øt
    
    üìä THAM S·ªê:
        image (np.ndarray): ·∫¢nh ƒë·∫ßu v√†o
    
    ‚úÖ HI·ªÜU QU·∫¢:
        - TƒÉng ƒë·ªô s·∫Øc n√©t nhanh
        - ƒê∆°n gi·∫£n, 1 convolution
        - L√†m n·ªïi texture
    
    ‚ö†Ô∏è CH√ö √ù:
        - C√≥ th·ªÉ tƒÉng nhi·ªÖu
        - Kh√¥ng d√πng cho ·∫£nh nhi·ªÖu nhi·ªÅu
        - Blur tr∆∞·ªõc khi sharpen n·∫øu c·∫ßn
    
    üí° ·ª®NG D·ª§NG:
        - C·∫£i thi·ªán ·∫£nh blur
        - TƒÉng c∆∞·ªùng texture
        - Post-processing cho ·∫£nh ch·ª•p
    """
    # Laplacian kernel
    kernel = np.array([[-1, -1, -1],
                       [-1,  9, -1],
                       [-1, -1, -1]], dtype=np.float64)
    
    result = convolve2d(image, kernel)
    return np.clip(result, 0, 255).astype(np.uint8)


# ==================== UTILITY FUNCTIONS ====================

def rgb_to_grayscale(image: np.ndarray) -> np.ndarray:
    """
    Chuy·ªÉn RGB sang grayscale theo c√¥ng th·ª©c:
    Gray = 0.299*R + 0.587*G + 0.114*B
    """
    if len(image.shape) == 2:
        return image
    
    return (0.299 * image[:, :, 0] + 
            0.587 * image[:, :, 1] + 
            0.114 * image[:, :, 2]).astype(np.uint8)
